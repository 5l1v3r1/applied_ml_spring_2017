{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission Information:\n",
    "\n",
    "### Team Member 1:\n",
    "* UNI: ia2221\n",
    "* Name: Ignacio Aranguren\n",
    "* Team Name: nachoaz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step0 - Import Libraries, Load Data [0 points]\n",
    "\n",
    "This is the basic step where you can load the data and create train and test sets for internal validation as per your convinience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib inline\n",
    "\n",
    "from __future__ import division\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import fancyimpute\n",
    "import mglearn\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import (train_test_split, \n",
    "     GridSearchCV, cross_val_score, cross_val_predict, StratifiedShuffleSplit)\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import Imputer\n",
    "from imblearn.pipeline import Pipeline as imb_Pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.ensemble import VotingClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "from sklearn.externals import joblib\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "orig_data = pd.read_csv('final_data//data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# orig_data.iloc[0:10,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do these different data values represent? Which ones should we not use? (Remember: we're trying to predict whether or not a person will buy a certain one of the bank's products, but we don't want to even bother the ones that are highly unlikely to buy. So we have to use features that are available before making the promotional call to that person.)\n",
    "\n",
    "Let's also take this as an opportunity to see what kinds of features we're working with and the possible values they can take on are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# !cat data/data_dictionary.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see that we have 20 features, 10 of which are numeric and 10 of which are categorical. To avoid using information that wouldn't be available before the first call, we're instructed not to use the feature 'duration'; everything else we can use.\n",
    "\n",
    "Let's get rid of that feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = orig_data.drop('duration', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now split our data into a train set and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     data.drop('subscribed', axis=1).values, \n",
    "     data['subscribed'].values,\n",
    "     stratify=data['subscribed'].values,\n",
    "     random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Step1 - Exploration and Preparation [10 points]\n",
    "\n",
    "In this step, we expect you to look into the data and try to understand it before modeling. This understanding may lead to some basic data preparation steps which are common across the two model sets required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>education</th>\n",
       "      <th>credit_default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>campaign</th>\n",
       "      <th>prev_days</th>\n",
       "      <th>prev_contacts</th>\n",
       "      <th>prev_outcomes</th>\n",
       "      <th>emp_var_rate</th>\n",
       "      <th>cons_price_idx</th>\n",
       "      <th>cons_conf_idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr_employed</th>\n",
       "      <th>subscribed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>thu</td>\n",
       "      <td>15</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.17826</td>\n",
       "      <td>94.2367</td>\n",
       "      <td>-37.0486</td>\n",
       "      <td>4.74608</td>\n",
       "      <td>5192</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>single</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>apr</td>\n",
       "      <td>fri</td>\n",
       "      <td>4</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>failure</td>\n",
       "      <td>-2.00094</td>\n",
       "      <td>94.1037</td>\n",
       "      <td>-46.0965</td>\n",
       "      <td>1.42721</td>\n",
       "      <td>5096</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>single</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>jun</td>\n",
       "      <td>fri</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.33155</td>\n",
       "      <td>94.79</td>\n",
       "      <td>-41.7284</td>\n",
       "      <td>4.99052</td>\n",
       "      <td>5227</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>divorced</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jul</td>\n",
       "      <td>tue</td>\n",
       "      <td>8</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.33587</td>\n",
       "      <td>94.5252</td>\n",
       "      <td>-42.9314</td>\n",
       "      <td>5.07024</td>\n",
       "      <td>5233</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>jun</td>\n",
       "      <td>fri</td>\n",
       "      <td>3</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.46837</td>\n",
       "      <td>94.1738</td>\n",
       "      <td>-42.6451</td>\n",
       "      <td>5.11396</td>\n",
       "      <td>5228</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  age           job marital_status          education credit_default housing  \\\n",
       "0  52   blue-collar        married           basic.4y        unknown      no   \n",
       "1  41   blue-collar         single           basic.6y        unknown     yes   \n",
       "2  36  entrepreneur         single  university.degree             no     yes   \n",
       "3  46   blue-collar       divorced            unknown             no      no   \n",
       "4  51    management        married  university.degree             no     yes   \n",
       "\n",
       "  loan    contact month day_of_week campaign prev_days prev_contacts  \\\n",
       "0   no  telephone   may         thu       15       999             0   \n",
       "1   no   cellular   apr         fri        4       999             1   \n",
       "2   no  telephone   jun         fri        1       999             0   \n",
       "3   no   cellular   jul         tue        8       999             0   \n",
       "4   no  telephone   jun         fri        3       999             0   \n",
       "\n",
       "  prev_outcomes emp_var_rate cons_price_idx cons_conf_idx euribor3m  \\\n",
       "0   nonexistent      1.17826        94.2367      -37.0486   4.74608   \n",
       "1       failure     -2.00094        94.1037      -46.0965   1.42721   \n",
       "2   nonexistent      1.33155          94.79      -41.7284   4.99052   \n",
       "3   nonexistent      1.33587        94.5252      -42.9314   5.07024   \n",
       "4   nonexistent      1.46837        94.1738      -42.6451   5.11396   \n",
       "\n",
       "  nr_employed subscribed  \n",
       "0        5192         no  \n",
       "1        5096         no  \n",
       "2        5227         no  \n",
       "3        5233         no  \n",
       "4        5228         no  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.DataFrame(X_train, columns=data.columns[:-1])\n",
    "train_df['subscribed'] = y_train\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've already seen what kind of variables we're working with. Let's now see how they're distributed and think about how we might encode or transform them.\n",
    "\n",
    "More specifically, let's see what the categories are for categorical variables, and let's look for differences in spelling and capitalization that might require preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I should convert the data types of the noncategorical features to numeric. That way, I'll then more easily be able to see the different values that the categorical features take on, and perhaps do some plotting (barcharts for categorical features, a scatterplot of the numerical features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               float64\n",
       "job                object\n",
       "marital_status     object\n",
       "education          object\n",
       "credit_default     object\n",
       "housing            object\n",
       "loan               object\n",
       "contact            object\n",
       "month              object\n",
       "day_of_week        object\n",
       "campaign          float64\n",
       "prev_days           int64\n",
       "prev_contacts       int64\n",
       "prev_outcomes      object\n",
       "emp_var_rate      float64\n",
       "cons_price_idx    float64\n",
       "cons_conf_idx     float64\n",
       "euribor3m         float64\n",
       "nr_employed       float64\n",
       "subscribed         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in train_df.columns:\n",
    "    if isinstance(train_df[col][0], int):\n",
    "        train_df[col] = train_df[col].apply(pd.to_numeric, errors='coerce')\n",
    "    elif isinstance(train_df[col][0], float):\n",
    "        train_df[col] = train_df[col].apply(pd.to_numeric, errors='coerce')\n",
    "        \n",
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It stands out to me that age got converted to a float, although I'd think that the measurements on that feature for all examples would be an integer. I'll investigate this further by looking at remainders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import floor\n",
    "all([num == floor(num) for num in train_df['age']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it looks like they're all integers. I'll move forward for now. Back to checking what categories each categorical variable takes on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "job\n",
      "admin.           6297\n",
      "blue-collar      5587\n",
      "technician       4059\n",
      "services         2362\n",
      "management       1751\n",
      "retired          1026\n",
      "entrepreneur      887\n",
      "self-employed     817\n",
      "housemaid         631\n",
      "unemployed        578\n",
      "student           531\n",
      "unknown           186\n",
      "Name: job, dtype: int64\n",
      "\n",
      "marital_status\n",
      "married     14961\n",
      "single       6958\n",
      "divorced     2749\n",
      "unknown        44\n",
      "Name: marital_status, dtype: int64\n",
      "\n",
      "education\n",
      "university.degree      7293\n",
      "high.school            5674\n",
      "basic.9y               3684\n",
      "professional.course    3150\n",
      "basic.4y               2457\n",
      "basic.6y               1398\n",
      "unknown                1045\n",
      "illiterate               11\n",
      "Name: education, dtype: int64\n",
      "\n",
      "credit_default\n",
      "no         19570\n",
      "unknown     5140\n",
      "yes            2\n",
      "Name: credit_default, dtype: int64\n",
      "\n",
      "housing\n",
      "yes        12838\n",
      "no         11284\n",
      "unknown      590\n",
      "Name: housing, dtype: int64\n",
      "\n",
      "loan\n",
      "no         20483\n",
      "yes         3639\n",
      "unknown      590\n",
      "Name: loan, dtype: int64\n",
      "\n",
      "contact\n",
      "cellular     15703\n",
      "telephone     9009\n",
      "Name: contact, dtype: int64\n",
      "\n",
      "month\n",
      "may    8220\n",
      "jul    4309\n",
      "aug    3670\n",
      "jun    3235\n",
      "nov    2488\n",
      "apr    1584\n",
      "oct     407\n",
      "sep     348\n",
      "mar     329\n",
      "dec     122\n",
      "Name: month, dtype: int64\n",
      "\n",
      "day_of_week\n",
      "thu    5210\n",
      "mon    5020\n",
      "wed    4923\n",
      "tue    4836\n",
      "fri    4723\n",
      "Name: day_of_week, dtype: int64\n",
      "\n",
      "prev_outcomes\n",
      "nonexistent    21330\n",
      "failure         2533\n",
      "success          849\n",
      "Name: prev_outcomes, dtype: int64\n",
      "\n",
      "subscribed\n",
      "no     21928\n",
      "yes     2784\n",
      "Name: subscribed, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for col in train_df.select_dtypes(exclude=['int64', 'float64']).columns:\n",
    "     print('\\n{}\\n{}'.format(col, train_df[col].value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above summary is a good way to get a detailed view of the breakdown of categories by variable. For a quicker and more qualitative view, it's easier to draw barcharts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA30AAAJ2CAYAAADrOuvOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nX0RERERExAhLpS8iIiIiImKE/X/R1R0HpKEiugAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff25bc57400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axarr = plt.subplots(2, 5)\n",
    "cat_cols = train_df.select_dtypes(exclude=['int64', 'float64']).columns\n",
    "i = 0\n",
    "\n",
    "for x in np.arange(2):\n",
    "    for y in np.arange(5):\n",
    "        x_pos = np.arange(len(train_df[cat_cols[i]].value_counts().keys()))\n",
    "        vals = train_df[cat_cols[i]].value_counts().values\n",
    "        axarr[x,y].bar(x_pos, vals)\n",
    "        axarr[x,y].set_xticks(x_pos)\n",
    "        axarr[x,y].set_xticklabels(train_df[cat_cols[i]].value_counts().keys(), rotation=90, size='small')\n",
    "        axarr[x,y].set_title(cat_cols[i])\n",
    "        i+=1\n",
    "\n",
    "fig.subplots_adjust(wspace=0.95, hspace=0.5)\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I build a scatterplot matrix to look at the continuous variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # the rotating of the axes here was done by following the example in:\n",
    "# # http://stackoverflow.com/questions/26975089/making-the-labels-of-the-scatterplot-vertical-and-horizontal-in-pandas\n",
    "\n",
    "# max_prev_days = sorted(set(train_df['prev_days'].values), reverse=True)[1]\n",
    "\n",
    "# axs = pd.scatter_matrix(train_df.select_dtypes(exclude=['object']), c=[1 if y == 'yes' else 0 for y in y_train])\n",
    "# n = len(train_df.select_dtypes(exclude=['object']).columns)\n",
    "\n",
    "# for x in range(n):\n",
    "#     for y in range(n):\n",
    "#         # to get the axis of subplots\n",
    "#         ax = axs[x, y]\n",
    "        \n",
    "#         if x == 2:\n",
    "#             ax.set_ylim([0, max_prev_days])\n",
    "            \n",
    "#         if y == 2:\n",
    "#             ax.set_xlim([0, max_prev_days])\n",
    "            \n",
    "#         # to make x axis name vertical  \n",
    "#         ax.xaxis.label.set_rotation(90)\n",
    "#         ax.xaxis.label.set_size(6)\n",
    "#         for tick in ax.xaxis.get_major_ticks():\n",
    "#             tick.label.set_fontsize(6)\n",
    "        \n",
    "#         # to make y axis name horizontal \n",
    "#         ax.yaxis.label.set_rotation(0)\n",
    "#         ax.yaxis.label.set_size(6)\n",
    "#         for tick in ax.yaxis.get_major_ticks():\n",
    "#             tick.label.set_fontsize(6)\n",
    "        \n",
    "#         # to make sure y axis names are outside the plot area\n",
    "#         ax.yaxis.labelpad = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I see that some of my numerical variables (such as `emp_var_rate`, `euribor3m`, and `nr_employed`) seem to be very much not normally distributed. I also see that most of my variables have different ranges. This indicates that pre-processing will be required, especially for fitting linear models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the ranges of my categorical variables are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# my_boxplot = plt.boxplot(train_df.select_dtypes(exclude=['object']).values)\n",
    "# my_ticks = plt.xticks(np.arange(1, train_df.select_dtypes(exclude=['object']).values.shape[1]+1), \n",
    "#           train_df.select_dtypes(exclude=['object']).keys(), rotation=30, ha='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some of the ways we might transform this, to try to gain some intuition as to which transformation might be best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# my_boxplot = plt.boxplot(RobustScaler().fit_transform(train_df.select_dtypes(exclude=['object']).values))\n",
    "# my_ticks = plt.xticks(np.arange(1, train_df.select_dtypes(exclude=['object']).values.shape[1]+1), \n",
    "#           train_df.select_dtypes(exclude=['object']).keys(), rotation=30, ha='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# my_boxplot = plt.boxplot(MinMaxScaler().fit_transform(train_df.select_dtypes(exclude=['object']).values))\n",
    "# my_ticks = plt.xticks(np.arange(1, train_df.select_dtypes(exclude=['object']).values.shape[1]+1), \n",
    "#           train_df.select_dtypes(exclude=['object']).keys(), rotation=30, ha='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also think about what missing values we might have, and how we might impute them. We know from the data dictionary that when prev_days is 999, that means that that particular client hasn't been contacted about an offer before. This is valuable information to keep. If we were to one-hot encode our data, we'll end up with a feature that is called something like `prev_days_is_999` which will take on a value of 1 when `prev_days` is 999 (ie when the client has never before been contacted), and a value of 0 when `prev_days` is _not_ 999 (ie when the client has been contacted before); we can thereore think of `prev_days_is_999` as `never_contacted`. But one-hot encoding this particular variable will result in too many added variables; moreover, it'd be more interpretable (and probably better for modeling) to treat this as a continuous variable. Therefore, what we'll do is we'll create a `has_been_contacted_before` categorical variable and we'll leave `prev_days` as a numerical variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>education</th>\n",
       "      <th>credit_default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>prev_days</th>\n",
       "      <th>prev_contacts</th>\n",
       "      <th>prev_outcomes</th>\n",
       "      <th>emp_var_rate</th>\n",
       "      <th>cons_price_idx</th>\n",
       "      <th>cons_conf_idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr_employed</th>\n",
       "      <th>never_contacted</th>\n",
       "      <th>subscribed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52.0</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>thu</td>\n",
       "      <td>...</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.178261</td>\n",
       "      <td>94.236694</td>\n",
       "      <td>-37.048583</td>\n",
       "      <td>4.746075</td>\n",
       "      <td>5192.0</td>\n",
       "      <td>True</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41.0</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>single</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>apr</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>failure</td>\n",
       "      <td>-2.000945</td>\n",
       "      <td>94.103725</td>\n",
       "      <td>-46.096535</td>\n",
       "      <td>1.427209</td>\n",
       "      <td>5096.0</td>\n",
       "      <td>True</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.0</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>single</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>jun</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.331550</td>\n",
       "      <td>94.790008</td>\n",
       "      <td>-41.728380</td>\n",
       "      <td>4.990515</td>\n",
       "      <td>5227.0</td>\n",
       "      <td>True</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46.0</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>divorced</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jul</td>\n",
       "      <td>tue</td>\n",
       "      <td>...</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.335875</td>\n",
       "      <td>94.525150</td>\n",
       "      <td>-42.931450</td>\n",
       "      <td>5.070245</td>\n",
       "      <td>5233.0</td>\n",
       "      <td>True</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51.0</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>jun</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.468371</td>\n",
       "      <td>94.173802</td>\n",
       "      <td>-42.645052</td>\n",
       "      <td>5.113962</td>\n",
       "      <td>5228.0</td>\n",
       "      <td>True</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age           job marital_status          education credit_default  \\\n",
       "0  52.0   blue-collar        married           basic.4y        unknown   \n",
       "1  41.0   blue-collar         single           basic.6y        unknown   \n",
       "2  36.0  entrepreneur         single  university.degree             no   \n",
       "3  46.0   blue-collar       divorced            unknown             no   \n",
       "4  51.0    management        married  university.degree             no   \n",
       "\n",
       "  housing loan    contact month day_of_week    ...      prev_days  \\\n",
       "0      no   no  telephone   may         thu    ...            999   \n",
       "1     yes   no   cellular   apr         fri    ...            999   \n",
       "2     yes   no  telephone   jun         fri    ...            999   \n",
       "3      no   no   cellular   jul         tue    ...            999   \n",
       "4     yes   no  telephone   jun         fri    ...            999   \n",
       "\n",
       "   prev_contacts  prev_outcomes emp_var_rate  cons_price_idx  cons_conf_idx  \\\n",
       "0              0    nonexistent     1.178261       94.236694     -37.048583   \n",
       "1              1        failure    -2.000945       94.103725     -46.096535   \n",
       "2              0    nonexistent     1.331550       94.790008     -41.728380   \n",
       "3              0    nonexistent     1.335875       94.525150     -42.931450   \n",
       "4              0    nonexistent     1.468371       94.173802     -42.645052   \n",
       "\n",
       "   euribor3m  nr_employed  never_contacted subscribed  \n",
       "0   4.746075       5192.0             True         no  \n",
       "1   1.427209       5096.0             True         no  \n",
       "2   4.990515       5227.0             True         no  \n",
       "3   5.070245       5233.0             True         no  \n",
       "4   5.113962       5228.0             True         no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['never_contacted'] = train_df['prev_days'] == 999\n",
    "train_df = train_df[list(train_df.columns[:-2]) + list([train_df.columns[-1]]) + list([train_df.columns[-2]])]\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also see that a lot of our categorical variables (`job`, `marital_status`, `education`, `credit_default`, `housing`, `loan`) have an 'unknown' category. We can treat these as an additional category or state that each of these values can take on, and so one-hot encoding will take care of this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now do one-hot encoding of our data. To avoid to problem where not all categories are represented in the converted data, IMLP recommends that we do this using the entire dataset (train and test), or that we do this using our train data but make sure that the names of the transformed columns are consistent to make sure that the semantics remain the same.\n",
    "\n",
    "I'll do the former."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I build a test_df, convert data types, and concatenate test_df and train_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(X_test, columns=data.columns[:-1])\n",
    "test_df['subscribed'] = y_test\n",
    "\n",
    "for col in test_df.columns:\n",
    "    if isinstance(test_df[col][0], int):\n",
    "        test_df[col] = test_df[col].apply(pd.to_numeric, errors='coerce')\n",
    "    elif isinstance(test_df[col][0], float):\n",
    "        test_df[col] = test_df[col].apply(pd.to_numeric, errors='coerce')\n",
    "        \n",
    "test_df['never_contacted'] = test_df['prev_days'] == 999\n",
    "test_df = test_df[list(test_df.columns[:-2]) + list([test_df.columns[-1]]) + list([test_df.columns[-2]])]\n",
    "        \n",
    "c_df = pd.concat([train_df, test_df], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I get the dummies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>campaign</th>\n",
       "      <th>prev_days</th>\n",
       "      <th>prev_contacts</th>\n",
       "      <th>emp_var_rate</th>\n",
       "      <th>cons_price_idx</th>\n",
       "      <th>cons_conf_idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr_employed</th>\n",
       "      <th>never_contacted</th>\n",
       "      <th>...</th>\n",
       "      <th>month_sep</th>\n",
       "      <th>day_of_week_fri</th>\n",
       "      <th>day_of_week_mon</th>\n",
       "      <th>day_of_week_thu</th>\n",
       "      <th>day_of_week_tue</th>\n",
       "      <th>day_of_week_wed</th>\n",
       "      <th>prev_outcomes_failure</th>\n",
       "      <th>prev_outcomes_nonexistent</th>\n",
       "      <th>prev_outcomes_success</th>\n",
       "      <th>subscribed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.938053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.178261</td>\n",
       "      <td>94.236694</td>\n",
       "      <td>-37.048583</td>\n",
       "      <td>4.746075</td>\n",
       "      <td>5192.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.938053</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.000945</td>\n",
       "      <td>94.103725</td>\n",
       "      <td>-46.096535</td>\n",
       "      <td>1.427209</td>\n",
       "      <td>5096.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.938053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.331550</td>\n",
       "      <td>94.790008</td>\n",
       "      <td>-41.728380</td>\n",
       "      <td>4.990515</td>\n",
       "      <td>5227.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.938053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.335875</td>\n",
       "      <td>94.525150</td>\n",
       "      <td>-42.931450</td>\n",
       "      <td>5.070245</td>\n",
       "      <td>5233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.938053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.468371</td>\n",
       "      <td>94.173802</td>\n",
       "      <td>-42.645052</td>\n",
       "      <td>5.113962</td>\n",
       "      <td>5228.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  campaign  prev_days  prev_contacts  emp_var_rate  cons_price_idx  \\\n",
       "0  52.0      15.0   5.938053            0.0      1.178261       94.236694   \n",
       "1  41.0       4.0   5.938053            1.0     -2.000945       94.103725   \n",
       "2  36.0       1.0   5.938053            0.0      1.331550       94.790008   \n",
       "3  46.0       8.0   5.938053            0.0      1.335875       94.525150   \n",
       "4  51.0       3.0   5.938053            0.0      1.468371       94.173802   \n",
       "\n",
       "   cons_conf_idx  euribor3m  nr_employed  never_contacted     ...      \\\n",
       "0     -37.048583   4.746075       5192.0              1.0     ...       \n",
       "1     -46.096535   1.427209       5096.0              1.0     ...       \n",
       "2     -41.728380   4.990515       5227.0              1.0     ...       \n",
       "3     -42.931450   5.070245       5233.0              1.0     ...       \n",
       "4     -42.645052   5.113962       5228.0              1.0     ...       \n",
       "\n",
       "   month_sep  day_of_week_fri  day_of_week_mon  day_of_week_thu  \\\n",
       "0        0.0              0.0              0.0              1.0   \n",
       "1        0.0              1.0              0.0              0.0   \n",
       "2        0.0              1.0              0.0              0.0   \n",
       "3        0.0              0.0              0.0              0.0   \n",
       "4        0.0              1.0              0.0              0.0   \n",
       "\n",
       "   day_of_week_tue  day_of_week_wed  prev_outcomes_failure  \\\n",
       "0              0.0              0.0                    0.0   \n",
       "1              0.0              0.0                    1.0   \n",
       "2              0.0              0.0                    0.0   \n",
       "3              1.0              0.0                    0.0   \n",
       "4              0.0              0.0                    0.0   \n",
       "\n",
       "   prev_outcomes_nonexistent  prev_outcomes_success  subscribed  \n",
       "0                        1.0                    0.0           0  \n",
       "1                        0.0                    0.0           0  \n",
       "2                        1.0                    0.0           0  \n",
       "3                        1.0                    0.0           0  \n",
       "4                        1.0                    0.0           0  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc_df = pd.get_dummies(c_df)\n",
    "dc_df.loc[dc_df['prev_days'] == 999, 'prev_days'] = np.nan\n",
    "dc_df = dc_df.drop(['subscribed_no'], axis=1)\n",
    "idc_df = pd.DataFrame(Imputer(strategy=\"mean\").fit_transform(dc_df.drop(['subscribed_yes'], axis=1).values))\n",
    "#idc_df = pd.DataFrame(fancyimpute.MICE(verbose=0).complete(dc_df.drop(['subscribed_yes'], axis=1).values))\n",
    "idc_df.columns = list(dc_df.drop(['subscribed_yes'], axis=1).columns)\n",
    "idc_df['subscribed'] = dc_df['subscribed_yes'].values\n",
    "\n",
    "etrain_df = idc_df.iloc[:train_df.shape[0],:]\n",
    "etest_df = idc_df.iloc[train_df.shape[0]:,:]\n",
    "\n",
    "etrain_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we note that there's the issue of class imbalance: that is, there's many more of the negative class than there is of the positive class. For simplicity and speed, we'll be doing random undersampling of the majority class to handle this; it will be done as part of a pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    29238\n",
       "1     3712\n",
       "Name: subscribed, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idc_df['subscribed'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To encapsulate all of the general preprocessing steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache\t    hw3_benchmarks.ipynb      hw3_starter_notebook_bla.ipynb\r\n",
      "final_data  hw3_solution_Apr11.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_partitioned_data():\n",
    "    o_data = pd.read_csv('final_data/data.csv')\n",
    "    #raw_h_data = pd.read_csv('data/holdout.csv')\n",
    "    \n",
    "    data = o_data.drop(['duration'], axis=1)\n",
    "    #raw_h_data = raw_h_data.drop(['duration'], axis=1)\n",
    "    \n",
    "    data['subscribed'] = pd.Series(\n",
    "        [1 if val=='yes' else 0 for val in data['subscribed'].values]\n",
    "    )\n",
    "    \n",
    "    raw_X_train, raw_X_test, raw_y_train, raw_y_test = train_test_split(\n",
    "        data.drop('subscribed', axis=1).values, \n",
    "        data['subscribed'].values,\n",
    "        stratify=data['subscribed'].values,\n",
    "        random_state=0)\n",
    "    \n",
    "    return raw_X_train, raw_X_test, raw_y_train, raw_y_test#, raw_h_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class CategoricalTransformer(BaseEstimator, TransformerMixin):\n",
    "    'For this, I followed the example in: https://tomaugspurger.github.io/categorical-pipelines.html'\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.transformed_columns_ = [u'age', u'campaign', u'prev_days', u'prev_contacts', \n",
    "            u'emp_var_rate', u'cons_price_idx', u'cons_conf_idx', u'euribor3m', u'nr_employed',\n",
    "            u'job_management', u'job_retired', u'job_self-employed', u'job_unknown',\n",
    "            u'job_unemployed', u'job_housemaid', u'job_admin.', u'job_entrepreneur',\n",
    "            u'job_services', u'job_student', u'job_technician', u'job_blue-collar',\n",
    "            u'marital_status_unknown', u'marital_status_single',\n",
    "            u'marital_status_married', u'marital_status_divorced',\n",
    "            u'education_basic.9y', u'education_illiterate', u'education_basic.4y',\n",
    "            u'education_unknown', u'education_basic.6y', u'education_high.school',\n",
    "            u'education_professional.course', u'education_university.degree',\n",
    "            u'credit_default_unknown', u'credit_default_yes', u'credit_default_no',\n",
    "            u'housing_unknown', u'housing_yes', u'housing_no', u'loan_unknown',\n",
    "            u'loan_yes', u'loan_no', u'contact_telephone', u'contact_cellular',\n",
    "            u'month_mar', u'month_apr', u'month_may',\n",
    "            u'month_jun', u'month_jul', u'month_aug', u'month_sep', u'month_oct',\n",
    "            u'month_nov', u'month_dec', u'day_of_week_mon', u'day_of_week_tue',\n",
    "            u'day_of_week_wed', u'day_of_week_thu', u'day_of_week_fri', u'prev_outcomes_failure',\n",
    "            u'prev_outcomes_success', u'prev_outcomes_nonexistent',\n",
    "            u'never_contacted_True', u'never_contacted_False']\n",
    "    \n",
    "    def fit(self, X, y=None, *args, **kwargs):\n",
    "        # fit should only take X and y as parameters\n",
    "        # Even if your model is unsupervised, you need to accept a y argument!\n",
    "        # Model fitting code goes here\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None, *args, **kwargs):\n",
    "        # transform takes as parameter only X\n",
    "        # Apply some transformation to X\n",
    "        tdf = pd.DataFrame(X)\n",
    "        tdf.columns = ['age', 'job', 'marital_status', 'education',\n",
    "                      'credit_default', 'housing', 'loan', 'contact',\n",
    "                      'month', 'day_of_week', 'campaign', 'prev_days',\n",
    "                      'prev_contacts', 'prev_outcomes', 'emp_var_rate',\n",
    "                      'cons_price_idx', 'cons_conf_idx', 'euribor3m',\n",
    "                      'nr_employed']\n",
    "        tdf['never_contacted'] = pd.Series(['True' if val else 'False' for val in (tdf['prev_days'] == 999).values])\n",
    "\n",
    "        jobs = ['management', 'retired', 'self-employed', \n",
    "                'unknown', 'unemployed', 'housemaid', 'admin.', \n",
    "                'entrepreneur', 'services', 'student', \n",
    "                'technician', 'blue-collar']\n",
    "        marital_statuses = ['unknown', 'single', 'married', 'divorced']\n",
    "        education_levels = ['basic.9y', 'illiterate', 'basic.4y', \n",
    "                            'unknown', 'basic.6y', 'high.school', \n",
    "                            'professional.course', 'university.degree']\n",
    "        credit_default_levels = ['unknown', 'yes', 'no']\n",
    "        housing_levels = ['unknown', 'yes', 'no']\n",
    "        loan_levels = ['unknown', 'yes', 'no']\n",
    "        contact_levels = ['telephone', 'cellular']\n",
    "        month_levels = ['mar', 'aug', 'sep', 'apr', 'jun', 'jul', \n",
    "                        'may', 'nov', 'dec', 'oct']\n",
    "        day_of_week_levels = ['thu', 'fri', 'mon', 'tue', 'wed']\n",
    "        prev_outcomes = ['failure', 'success', 'nonexistent']\n",
    "        never_contacted_levels = ['True', 'False']\n",
    "\n",
    "        for col in tdf.columns:\n",
    "            if isinstance(tdf[col][0], int):\n",
    "                tdf[col] = tdf[col].astype(np.int64)\n",
    "            elif isinstance(tdf[col][0], float):\n",
    "                tdf[col] = tdf[col].astype(np.float64)\n",
    "            elif isinstance(tdf[col][0], np.bool_):\n",
    "                tdf[col] = tdf[col].astype(np.int64)\n",
    "        \n",
    "        tdf['job'] = pd.Categorical(tdf.job, categories=jobs)\n",
    "        tdf['marital_status'] = pd.Categorical(tdf.marital_status, categories=marital_statuses)\n",
    "        tdf['education'] = pd.Categorical(tdf.education, categories=education_levels)\n",
    "        tdf['credit_default'] = pd.Categorical(tdf.credit_default, categories=credit_default_levels)\n",
    "        tdf['housing'] = pd.Categorical(tdf.housing, categories=housing_levels)\n",
    "        tdf['loan'] = pd.Categorical(tdf.loan, categories=loan_levels)\n",
    "        tdf['contact'] = pd.Categorical(tdf.contact, categories=contact_levels)\n",
    "        tdf['month'] = pd.Categorical(tdf.month, categories=month_levels)\n",
    "        tdf['day_of_week'] = pd.Categorical(tdf.day_of_week, categories=day_of_week_levels)\n",
    "        tdf['prev_outcomes'] = pd.Categorical(tdf.prev_outcomes, categories=prev_outcomes)\n",
    "        tdf['never_contacted'] = pd.Categorical(tdf.never_contacted, categories=never_contacted_levels)\n",
    "\n",
    "        pre_dummify_prev_days = tdf['prev_days']\n",
    "        \n",
    "        d_tdf = pd.get_dummies(tdf).reindex(columns=self.transformed_columns_)\n",
    "        \n",
    "        d_tdf['prev_days'] = pre_dummify_prev_days\n",
    "        d_tdf.loc[d_tdf['prev_days'] == 999, 'prev_days'] = np.nan\n",
    "                \n",
    "        return (d_tdf.values)\n",
    "        \n",
    "\n",
    "class FancyImputeTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, missing_values=np.nan):\n",
    "        # All parameters must be specified in the __init__ function\n",
    "        self.missing_values=missing_values\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        # fit should only take X and y as parameters\n",
    "        # Even if your model is unsupervised, you need to accept a y argument!\n",
    "        # Model fitting code goes here\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # transform takes as parameter only X\n",
    "        # Apply some transformation to X\n",
    "        X_transformed = fancyimpute.MICE(verbose=0).complete(X)\n",
    "        return X_transformed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (10000, 64)\n",
      "Shape of y_train: (10000,)\n",
      "Shape of X_test: (2500, 64)\n",
      "Shape of y_test: (2500,)\n"
     ]
    }
   ],
   "source": [
    "def get_transformed_data():\n",
    "    ct = CategoricalTransformer()\n",
    "    it = FancyImputeTransformer()\n",
    "    st = RobustScaler()\n",
    "\n",
    "    pipe = imb_Pipeline([\n",
    "            ('dummyencoding', ct),\n",
    "            ('imputing', it),\n",
    "            ('scaling', st),\n",
    "            ('sampling', RandomOverSampler()),\n",
    "        ])\n",
    "    \n",
    "    #raw_X_train, raw_X_test, raw_y_train, raw_y_test, raw_h_data = get_partitioned_data()\n",
    "    raw_X_train, raw_X_test, raw_y_train, raw_y_test = get_partitioned_data()\n",
    "    encoded_imputed_samples = pipe.fit_sample(raw_X_train, raw_y_train)\n",
    "    shuffled_df = pd.concat([pd.DataFrame(encoded_imputed_samples[0]), \n",
    "                             pd.DataFrame(encoded_imputed_samples[1], columns=['subscribed'])], \n",
    "                            axis=1).sample(frac=1)\n",
    "    \n",
    "    sss = StratifiedShuffleSplit(n_splits=2, train_size=10000, test_size=2500, random_state=0)\n",
    "    one_ind, _ = sss.split(shuffled_df.values[:,:-1], shuffled_df.values[:,-1])\n",
    "    \n",
    "    X_train = shuffled_df.values[one_ind[0],:-1]\n",
    "    y_train = shuffled_df.values[one_ind[0],-1]\n",
    "    \n",
    "    X_test = shuffled_df.values[one_ind[1],:-1]\n",
    "    y_test = shuffled_df.values[one_ind[1],-1]\n",
    "\n",
    "    #X_train = shuffled_df.drop(['subscribed'], axis=1).values\n",
    "    #y_train = shuffled_df['subscribed'].values\n",
    "    \n",
    "    test_pipe = imb_Pipeline([\n",
    "            ('dummyencoding', ct),\n",
    "            ('imputing', it),\n",
    "            ('scaling', st),\n",
    "        ])\n",
    "\n",
    "    #X_test = test_pipe.transform(raw_X_test)\n",
    "    #y_test = raw_y_test\n",
    "        \n",
    "    #h_data = np.hstack([raw_h_data[:,0].reshape(raw_h_data.shape[0], 1), test_pipe.transform(raw_h_data[:,1:])])\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test#, h_data\n",
    "\n",
    "#X_train, X_test, y_train, y_test, h_data = get_transformed_data()\n",
    "X_train, X_test, y_train, y_test = get_transformed_data()\n",
    "print(\"Shape of X_train: {}\".format(X_train.shape))\n",
    "print(\"Shape of y_train: {}\".format(y_train.shape))\n",
    "print(\"Shape of X_test: {}\".format(X_test.shape))\n",
    "print(\"Shape of y_test: {}\".format(y_test.shape))\n",
    "#print(\"Shape of h_data: {}\".format(h_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step2 - ModelSet1 [35 points]\n",
    "\n",
    "In this step, we expect you to perform the following steps relevant to the models you choose for set1:\n",
    "\n",
    "* feature engineering\n",
    "* validation\n",
    "* feature selection\n",
    "* final model selection\n",
    "\n",
    "You may select up to 5 models in this step for the purpose of final ensemble. Any classification algorithm covered in class apart from tree-based models can be tested here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this section, I'll first explore linear models.\n",
    "\n",
    "My plan is to first do a \"course adjustment\" grid search (over various preprocessing steps, models, and parameter settings), and then do a \"fine adjustment\" grid search.\n",
    "\n",
    "Then I'll use the results from the second grid search to select the 5 best models.\n",
    "\n",
    "In particular, I'll use kernelized SVMS; because they are very sensitive to the settings of the parameters and to the scaling of the data, I'll make sure to carry out additional pre-processing steps and will use grid searches to find the optimal parameter settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_set_1_results = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-003c84cdc5a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msvc_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvc_param_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"roc_auc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msvc_grid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best SVC CV: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvc_grid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/andy/checkout/scikit-learn/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    601\u001b[0m                                   \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m--> 603\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    604\u001b[0m           for parameters in candidate_params)\n\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/andy/checkout/scikit-learn/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/andy/checkout/scikit-learn/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/andy/checkout/scikit-learn/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/andy/checkout/scikit-learn/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/andy/checkout/scikit-learn/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/andy/checkout/scikit-learn/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/andy/checkout/scikit-learn/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/andy/checkout/scikit-learn/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m             \u001b[0mtrain_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/andy/checkout/scikit-learn/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'item'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/andy/checkout/scikit-learn/sklearn/metrics/scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, clf, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m                 \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0;31m# For multi-output multi-class estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/andy/checkout/scikit-learn/sklearn/svm/base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    525\u001b[0m             n_classes)\n\u001b[1;32m    526\u001b[0m         \"\"\"\n\u001b[0;32m--> 527\u001b[0;31m         \u001b[0mdec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function_shape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'ovr'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_ovr_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mdec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/andy/checkout/scikit-learn/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    388\u001b[0m             \u001b[0mdec_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m             \u001b[0mdec_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0;31m# In binary case, we need to flip the sign of coef, intercept and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/andy/checkout/scikit-learn/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_dense_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0msvm_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLIBSVM_IMPL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m             coef0=self.coef0, gamma=self._gamma)\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_sparse_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "svc_param_grid = {'gamma': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                  'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "svc_grid = GridSearchCV(SVC(), svc_param_grid, cv=5, scoring=\"roc_auc\")\n",
    "svc_grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best SVC CV: {}\".format(svc_grid.best_score_))\n",
    "print(\"Best SVC Test: {}\".format(svc_grid.score(X_test, y_test)))\n",
    "\n",
    "svc_results = pd.DataFrame(svc_grid.cv_results_)\n",
    "model_set_1_results = pd.concat([model_set_1_results, svc_results])\n",
    "svc_scores = np.array(svc_results.mean_test_score).reshape(6,6)\n",
    "\n",
    "svc_scores_image = mglearn.tools.heatmap(svc_scores, xlabel='gamma', xticklabels=svc_param_grid['gamma'],\n",
    "                                         ylabel='C', yticklabels=svc_param_grid['C'], cmap=\"viridis\")\n",
    "svc_colorbar = plt.colorbar(svc_scores_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see that we have reason to explore further with lower values of gamma (perhaps now [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svc_param_grid = {'gamma': [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1],\n",
    "                  'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "svc_grid = GridSearchCV(SVC(), svc_param_grid, cv=5, scoring=\"roc_auc\")\n",
    "svc_grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best SVC CV: {}\".format(svc_grid.best_score_))\n",
    "print(\"Best SVC Test: {}\".format(svc_grid.score(X_test, y_test)))\n",
    "\n",
    "svc_results = pd.DataFrame(svc_grid.cv_results_)\n",
    "model_set_1_results = pd.concat([model_set_1_results, svc_results])\n",
    "svc_scores = np.array(svc_results.mean_test_score).reshape(6,6)\n",
    "\n",
    "svc_scores_image = mglearn.tools.heatmap(svc_scores, xlabel='gamma', xticklabels=svc_param_grid['gamma'],\n",
    "                                         ylabel='C', yticklabels=svc_param_grid['C'], cmap=\"viridis\")\n",
    "svc_colorbar = plt.colorbar(svc_scores_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see that now we might want to explore larger values of C. Let's do [1, 10, 100, 1000, 10000, 100000]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-6779b53f1a81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msvc_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvc_param_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"roc_auc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msvc_grid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best SVC CV: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvc_grid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/andy/checkout/scikit-learn/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    601\u001b[0m                                   \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m--> 603\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    604\u001b[0m           for parameters in candidate_params)\n\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/andy/checkout/scikit-learn/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/andy/checkout/scikit-learn/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/andy/checkout/scikit-learn/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/andy/checkout/scikit-learn/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/andy/checkout/scikit-learn/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/andy/checkout/scikit-learn/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/andy/checkout/scikit-learn/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/andy/checkout/scikit-learn/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/andy/checkout/scikit-learn/sklearn/svm/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/andy/checkout/scikit-learn/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    252\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "svc_param_grid = {'gamma': [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1],\n",
    "                  'C': [1, 10, 100, 1000, 10000, 100000]}\n",
    "\n",
    "svc_grid = GridSearchCV(SVC(), svc_param_grid, cv=5, scoring=\"roc_auc\")\n",
    "svc_grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best SVC CV: {}\".format(svc_grid.best_score_))\n",
    "print(\"Best SVC Test: {}\".format(svc_grid.score(X_test, y_test)))\n",
    "\n",
    "svc_results = pd.DataFrame(svc_grid.cv_results_)\n",
    "model_set_1_results = pd.concat([model_set_1_results, svc_results])\n",
    "svc_scores = np.array(svc_results.mean_test_score).reshape(6,6)\n",
    "\n",
    "svc_scores_image = mglearn.tools.heatmap(svc_scores, xlabel='gamma', xticklabels=svc_param_grid['gamma'],\n",
    "                                         ylabel='C', yticklabels=svc_param_grid['C'], cmap=\"viridis\")\n",
    "svc_colorbar = plt.colorbar(svc_scores_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV] C=0.001 .........................................................\n",
      "[CV] .......................... C=0.001, score=0.763355, total=   0.0s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] ........................... C=0.01, score=0.772500, total=   0.0s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ............................ C=0.1, score=0.775753, total=   0.0s\n",
      "[CV] C=1 .............................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............................. C=1, score=0.774647, total=   0.1s\n",
      "[CV] C=10 ............................................................\n",
      "[CV] ............................. C=10, score=0.774247, total=   0.1s\n",
      "[CV] C=100 ...........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................ C=100, score=0.774155, total=   0.1s\n",
      "[CV] C=0.001 .........................................................\n",
      "[CV] .......................... C=0.001, score=0.781828, total=   0.0s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] ........................... C=0.01, score=0.788833, total=   0.0s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ............................ C=0.1, score=0.790705, total=   0.0s\n",
      "[CV] C=1 .............................................................\n",
      "[CV] .............................. C=1, score=0.790403, total=   0.1s\n",
      "[CV] C=10 ............................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................. C=10, score=0.790064, total=   0.1s\n",
      "[CV] C=100 ...........................................................\n",
      "[CV] ............................ C=100, score=0.790042, total=   0.1s\n",
      "[CV] C=0.001 .........................................................\n",
      "[CV] .......................... C=0.001, score=0.791486, total=   0.0s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] ........................... C=0.01, score=0.797030, total=   0.0s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ............................ C=0.1, score=0.798046, total=   0.0s\n",
      "[CV] C=1 .............................................................\n",
      "[CV] .............................. C=1, score=0.798558, total=   0.1s\n",
      "[CV] C=10 ............................................................\n",
      "[CV] ............................. C=10, score=0.798373, total=   0.1s\n",
      "[CV] C=100 ...........................................................\n",
      "[CV] ............................ C=100, score=0.798369, total=   0.1s\n",
      "[CV] C=0.001 .........................................................\n",
      "[CV] .......................... C=0.001, score=0.782214, total=   0.0s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] ........................... C=0.01, score=0.790694, total=   0.0s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ............................ C=0.1, score=0.793193, total=   0.1s\n",
      "[CV] C=1 .............................................................\n",
      "[CV] .............................. C=1, score=0.793646, total=   0.2s\n",
      "[CV] C=10 ............................................................\n",
      "[CV] ............................. C=10, score=0.793654, total=   0.1s\n",
      "[CV] C=100 ...........................................................\n",
      "[CV] ............................ C=100, score=0.793663, total=   0.1s\n",
      "[CV] C=0.001 .........................................................\n",
      "[CV] .......................... C=0.001, score=0.756300, total=   0.0s\n",
      "[CV] C=0.01 ..........................................................\n",
      "[CV] ........................... C=0.01, score=0.768211, total=   0.0s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ............................ C=0.1, score=0.773493, total=   0.1s\n",
      "[CV] C=1 .............................................................\n",
      "[CV] .............................. C=1, score=0.775098, total=   0.1s\n",
      "[CV] C=10 ............................................................\n",
      "[CV] ............................. C=10, score=0.775421, total=   0.1s\n",
      "[CV] C=100 ...........................................................\n",
      "[CV] ............................ C=100, score=0.775445, total=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    2.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LR CV: 0.7864704\n",
      "Best LR Test: 0.80706112\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "heatmap() missing 2 required positional arguments: 'ylabel' and 'yticklabels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-757ffd6e1657>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mlr_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_test_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mlr_scores_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmglearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxticklabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr_param_grid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"viridis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mlr_colorbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_scores_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: heatmap() missing 2 required positional arguments: 'ylabel' and 'yticklabels'"
     ]
    }
   ],
   "source": [
    "lr_param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "lr_grid = GridSearchCV(LogisticRegression(), lr_param_grid, cv=5, scoring=\"roc_auc\", verbose=10)\n",
    "lr_grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best LR CV: {}\".format(lr_grid.best_score_))\n",
    "print(\"Best LR Test: {}\".format(lr_grid.score(X_test, y_test)))\n",
    "\n",
    "lr_results = pd.DataFrame(lr_grid.cv_results_)\n",
    "model_set_1_results = pd.concat([model_set_1_results, lr_results])\n",
    "lr_scores = np.array(lr_results.mean_test_score).reshape(6,1)\n",
    "\n",
    "#lr_scores_image = mglearn.tools.heatmap(lr_scores, xlabel='C', xticklabels=lr_param_grid['C'], cmap=\"viridis\")\n",
    "\n",
    "lr_colorbar = plt.colorbar(lr_scores_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.7750366],\n",
       "       [ 0.7834536],\n",
       "       [ 0.786238 ],\n",
       "       [ 0.7864704],\n",
       "       [ 0.7863518],\n",
       "       [ 0.7863348]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now take a closer look at which were the best models from ModelSet1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_set_1_results.sort_values(by='mean_test_score', ascending=False).head()[['mean_test_score', 'params']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the 5 models that we pick are all SVCs (with the parameters as specified above)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step3 - ModelSet2 [35 points]\n",
    "\n",
    "In this step, we expect you to perform the following steps relevant to the models you choose for set2:\n",
    "\n",
    "* feature engineering\n",
    "* validation\n",
    "* feature selection\n",
    "* final model selection\n",
    "\n",
    "You may select up to 5 models in this step for the purpose of final ensemble. We encourage you to try decition tree, random forest and gradient boosted tree methods here and pick the one which you think works best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model_set_2_results = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# gb_param_grid = {'n_estimators': [100],\n",
    "#      'learning_rate': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# gb_grid = GridSearchCV(GradientBoostingClassifier(), gb_param_grid, cv=10, scoring=\"roc_auc\")\n",
    "# gb_grid.fit(X_train, y_train)\n",
    "\n",
    "# print(\"Best GB CV: {}\".format(gb_grid.best_score_))\n",
    "# print(\"Best GB Test: {}\".format(gb_grid.score(X_test, y_test)))\n",
    "\n",
    "# gb_results = pd.DataFrame(gb_grid.cv_results_)\n",
    "# model_set_2_results = pd.concat([model_set_2_results, gb_results])\n",
    "# gb_scores = np.array(gb_results.mean_test_score).reshape(6,1)\n",
    "\n",
    "# gb_scores_image = mglearn.tools.heatmap(gb_scores, xlabel='n_estimators', xticklabels=gb_param_grid['n_estimators'],\n",
    "#                           ylabel='learning_rate', yticklabels=gb_param_grid['learning_rate'], cmap=\"viridis\")\n",
    "# gb_colorbar = plt.colorbar(gb_scores_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# gb_param_grid = {'n_estimators': [100],\n",
    "#      'learning_rate': [0.1, 0.25, 0.5, 0.75, 1]}\n",
    "\n",
    "# gb_grid = GridSearchCV(GradientBoostingClassifier(), gb_param_grid, cv=10, scoring=\"roc_auc\")\n",
    "# gb_grid.fit(X_train, y_train)\n",
    "\n",
    "# print(\"Best GB CV: {}\".format(gb_grid.best_score_))\n",
    "# print(\"Best GB Test: {}\".format(gb_grid.score(X_test, y_test)))\n",
    "\n",
    "# gb_results = pd.DataFrame(gb_grid.cv_results_)\n",
    "# model_set_2_results = pd.concat([model_set_2_results, gb_results])\n",
    "# gb_scores = np.array(gb_results.mean_test_score).reshape(len(gb_param_grid['learning_rate']),1)\n",
    "\n",
    "# gb_scores_image = mglearn.tools.heatmap(gb_scores, xlabel='n_estimators', xticklabels=gb_param_grid['n_estimators'],\n",
    "#                           ylabel='learning_rate', yticklabels=gb_param_grid['learning_rate'], cmap=\"viridis\")\n",
    "# gb_colorbar = plt.colorbar(gb_scores_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gb_param_grid = {'n_estimators': [100],\n",
    "#      'learning_rate': [0.5, 0.6, 0.7, 0.8, 0.9, 1]}\n",
    "\n",
    "# gb_grid = GridSearchCV(GradientBoostingClassifier(), gb_param_grid, cv=10, scoring=\"roc_auc\")\n",
    "# gb_grid.fit(X_train, y_train)\n",
    "\n",
    "# print(\"Best GB CV: {}\".format(gb_grid.best_score_))\n",
    "# print(\"Best GB Test: {}\".format(gb_grid.score(X_test, y_test)))\n",
    "\n",
    "# gb_results = pd.DataFrame(gb_grid.cv_results_)\n",
    "# model_set_2_results = pd.concat([model_set_2_results, gb_results])\n",
    "# gb_scores = np.array(gb_results.mean_test_score).reshape(len(gb_param_grid['learning_rate']),1)\n",
    "\n",
    "# gb_scores_image = mglearn.tools.heatmap(gb_scores, xlabel='n_estimators', xticklabels=gb_param_grid['n_estimators'],\n",
    "#                           ylabel='learning_rate', yticklabels=gb_param_grid['learning_rate'], cmap=\"viridis\")\n",
    "# gb_colorbar = plt.colorbar(gb_scores_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gb_param_grid = {'n_estimators': [100],\n",
    "#      'learning_rate': [0.45, 0.475, 0.5, 0.525, 0.55, 0.575]}\n",
    "\n",
    "# gb_grid = GridSearchCV(GradientBoostingClassifier(), gb_param_grid, cv=10, scoring=\"roc_auc\")\n",
    "# gb_grid.fit(X_train, y_train)\n",
    "\n",
    "# print(\"Best GB CV: {}\".format(gb_grid.best_score_))\n",
    "# print(\"Best GB Test: {}\".format(gb_grid.score(X_test, y_test)))\n",
    "\n",
    "# gb_results = pd.DataFrame(gb_grid.cv_results_)\n",
    "# model_set_2_results = pd.concat([model_set_2_results, gb_results])\n",
    "# gb_scores = np.array(gb_results.mean_test_score).reshape(len(gb_param_grid['learning_rate']),1)\n",
    "\n",
    "# gb_scores_image = mglearn.tools.heatmap(gb_scores, xlabel='n_estimators', xticklabels=gb_param_grid['n_estimators'],\n",
    "#                           ylabel='learning_rate', yticklabels=gb_param_grid['learning_rate'], cmap=\"viridis\")\n",
    "# gb_colorbar = plt.colorbar(gb_scores_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rf_param_grid = {'n_estimators': [1000],\n",
    "#      'max_features': np.linspace(2,8, 5)/64} # here, i follow the recommendation from APM\n",
    "\n",
    "# rf_grid = GridSearchCV(RandomForestClassifier(), rf_param_grid, cv=10, scoring=\"roc_auc\")\n",
    "# rf_grid.fit(X_train, y_train)\n",
    "\n",
    "# # joblib.dump(rf_grid, 'rf_grid.pkl')\n",
    "\n",
    "# # rf_grid = joblib.load('rf_grid.pkl')\n",
    "\n",
    "# print(\"Best RF CV: {}\".format(rf_grid.best_score_))\n",
    "# print(\"Best RF Test: {}\".format(rf_grid.score(X_test, y_test)))\n",
    "\n",
    "# rf_results = pd.DataFrame(rf_grid.cv_results_)\n",
    "# model_set_2_results = pd.concat([model_set_2_results, rf_results])\n",
    "# rf_scores = np.array(rf_results.mean_test_score).reshape(5,1)\n",
    "\n",
    "# rf_scores_image = mglearn.tools.heatmap(rf_scores, xlabel='n_estimators', xticklabels=rf_param_grid['n_estimators'],\n",
    "#                           ylabel='max_features', yticklabels=rf_param_grid['max_features'], cmap=\"viridis\")\n",
    "# rf_colorbar = plt.colorbar(rf_scores_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model_set_2_results.sort_values(by='mean_test_score', ascending=False).head()[['mean_test_score', 'params']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the 5 models that we pick are all GradientBoostingClassifiers, with the parameters as specified above). Let's see the learning rates more in detail, though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for my_dict in model_set_2_results.sort_values(by='mean_test_score', ascending=False).head()[['mean_test_score', 'params']]['params']:\n",
    "#     print(\"learning_rate: {:.6f}\".format(my_dict['learning_rate']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step4 - Ensemble [20 points + 10 Bonus points]\n",
    "\n",
    "In this step, we expect you to use the models created before and create new predictions. You should definitely try poor man's stacking but we encourage you to think of different ensemble techniques as well. We will judge your creativity and improvement in model performance using ensemble models and you can potentially earn 10 bonus points here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "voting = VotingClassifier([\n",
    "#                            ('ms1_1', SVC(C=100, gamma=0.001, probability=True)),\n",
    "#                            ('ms1_2', SVC(C=100000, gamma=0.000001, probability=True)),\n",
    "#                            ('ms1_3', SVC(C=10000, gamma=0.0001, probability=True)),\n",
    "#                            ('ms1_4', SVC(C=10, gamma=0.01, probability=True)),\n",
    "#                            ('ms1_5', SVC(C=100, gamma=0.00001, probability=True)),\n",
    "                           ('ms2_1', GradientBoostingClassifier(n_estimators=100, learning_rate=0.525)),\n",
    "                           ('ms2_2', GradientBoostingClassifier(n_estimators=100, learning_rate=0.5)),\n",
    "                           ('ms2_3', GradientBoostingClassifier(n_estimators=100, learning_rate=0.575)),\n",
    "                           ('ms2_4', GradientBoostingClassifier(n_estimators=100, learning_rate=0.52)),\n",
    "                           ('ms2_5', GradientBoostingClassifier(n_estimators=100, learning_rate=0.51))\n",
    "                          ],\n",
    "                         voting='soft')\n",
    "\n",
    "num_of_estimators = len(voting.named_estimators.keys())\n",
    "reshaper = FunctionTransformer(lambda X_: np.rollaxis(X_, 1).reshape(-1,num_of_estimators*2)[:, 1::2],\n",
    "                               validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking CV ROC_AUC: 0.836304542121\n"
     ]
    }
   ],
   "source": [
    "first_stage = make_pipeline(voting, reshaper)\n",
    "transform_cv = cross_val_predict(first_stage, X_train, y_train, cv=3, method=\"transform\")\n",
    "second_stage = LogisticRegression(C=100).fit(transform_cv, y_train)\n",
    "\n",
    "cv_probs = second_stage.predict_proba(transform_cv)[:,1]\n",
    "print(\"Stacking CV ROC_AUC: {}\".format(\n",
    "        metrics.roc_auc_score(y_train, cv_probs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Test ROC_AUC: 0.769582586443\n"
     ]
    }
   ],
   "source": [
    "stacking = make_pipeline(first_stage, second_stage)\n",
    "stacking.fit(X_train, y_train)\n",
    "test_probs = stacking.predict_proba(X_test)[:,1]\n",
    "print(\"Stacking Test ROC_AUC: {}\".format(\n",
    "        metrics.roc_auc_score(y_test, test_probs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#write code below, you can make multiple cells\n",
    "assert metrics.roc_auc_score(y_train, cv_probs) > 0.65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def write_submission_csv(csv_name):\n",
    "#     h_probs = stacking.predict_proba(h_data[:,1:])[:,1]\n",
    "#     h_submission_arr = np.hstack([h_data[:,0].reshape(h_data.shape[0], 1), \n",
    "#                                   h_probs.reshape(h_data.shape[0], 1)])\n",
    "#     pd.DataFrame(h_submission_arr, columns=['ID', 'subscribed']).to_csv(csv_name, index=False)\n",
    "    \n",
    "# write_submission_csv('big_hopeful_submission.csv')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
