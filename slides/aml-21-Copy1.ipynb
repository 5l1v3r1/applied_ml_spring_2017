{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "plt.rcParams[\"figure.dpi\"] = 300\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import scale, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of text_train: <class 'list'>\n",
      "length of text_train: 25000\n",
      "text_train[1]:\n",
      "b'Words can\\'t describe how bad this movie is. I can\\'t explain it by writing only. You have too see it for yourself to get at grip of how horrible a movie really can be. Not that I recommend you to do that. There are so many clich\\xc3\\xa9s, mistakes (and all other negative things you can imagine) here that will just make you cry. To start with the technical first, there are a LOT of mistakes regarding the airplane. I won\\'t list them here, but just mention the coloring of the plane. They didn\\'t even manage to show an airliner in the colors of a fictional airline, but instead used a 747 painted in the original Boeing livery. Very bad. The plot is stupid and has been done many times before, only much, much better. There are so many ridiculous moments here that i lost count of it really early. Also, I was on the bad guys\\' side all the time in the movie, because the good guys were so stupid. \"Executive Decision\" should without a doubt be you\\'re choice over this one, even the \"Turbulence\"-movies are better. In fact, every other movie in the world is better than this one.'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files\n",
    "\n",
    "reviews_train = load_files(\"../data/aclImdb/train/\")\n",
    "# load_files returns a bunch, containing training texts and training labels\n",
    "text_train, y_train = reviews_train.data, reviews_train.target\n",
    "print(\"type of text_train: {}\".format(type(text_train)))\n",
    "print(\"length of text_train: {}\".format(len(text_train)))\n",
    "print(\"text_train[1]:\\n{}\".format(text_train[1]))\n",
    "text_train = [doc.replace(b\"<br />\", b\" \") for doc in text_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "text_train_sub, text_val, y_train_sub, y_val = train_test_split(\n",
    "    text_train, y_train, stratify=y_train, random_state=0)\n",
    "vect = CountVectorizer(min_df=2, stop_words=\"english\")\n",
    "X_train = vect.fit_transform(text_train_sub)\n",
    "X_val = vect.transform(text_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(C=.1).fit(X_train, y_train_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88095999999999997"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['what', 'is', 'my', 'purpose'], ['you', 'bring', 'butter']]\n"
     ]
    }
   ],
   "source": [
    "docs = [\"What is my purpose\", \"You bring butter\"]\n",
    "texts = [[token for token in doc.lower().split()] for doc in docs]\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(7 unique tokens: ['you', 'bring', 'butter', 'purpose', 'what']...)\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1), (6, 1)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_doc = \"what butter\"\n",
    "dictionary.doc2bow(new_doc.lower().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1), (3, 1)], [(4, 1), (5, 1), (6, 1)]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1), (3, 1)], [(4, 1), (5, 1), (6, 1)]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7x2 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 7 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim.matutils.corpus2csc(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x7 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 7 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = CountVectorizer().fit_transform(docs)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<gensim.matutils.Sparse2Corpus object at 0x7fcfb38ae940>\n",
      "[[(4, 1), (3, 1), (2, 1), (5, 1)], [(1, 1), (0, 1), (6, 1)]]\n"
     ]
    }
   ],
   "source": [
    "sparse_corpus = gensim.matutils.Sparse2Corpus(X.T)\n",
    "print(sparse_corpus)\n",
    "print(list(sparse_corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpus transformations with gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.5), (1, 0.5), (2, 0.5), (3, 0.5)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = gensim.models.TfidfModel(corpus)\n",
    "tfidf[corpus[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<gensim.interfaces.TransformedCorpus object at 0x7fcfb38aee48>\n",
      "[[(0, 0.5), (1, 0.5), (2, 0.5), (3, 0.5)], [(4, 0.5773502691896258), (5, 0.5773502691896258), (6, 0.5773502691896258)]]\n"
     ]
    }
   ],
   "source": [
    "print(tfidf[corpus])\n",
    "print(list(tfidf[corpus]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec with gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gensim import models\n",
    "w = models.KeyedVectors.load_word2vec_format(\n",
    "    '../GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w['queen'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000000, 300)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.syn0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['in', 'for', 'that', 'is', 'the', 'at', 'not', 'as', 'it', 'by',\n",
       "       'are', 'have', 'an', 'this', 'they', 'but', 'one', 'which', 'do',\n",
       "       'than', 'over', 'just', 'some', 'like', 'only', 'did', 'because',\n",
       "       'off', 'being', 'my', 'very', 'much', 'go', 'under', 'does', 'got',\n",
       "       'top', 'come', 'really', 'lot', 'find', 'thing', 'once', 'offer',\n",
       "       'feel', 'film', 'medical', 'terms', 'rather', 'certain', 'felt',\n",
       "       'consider', 'watch', 'parts', 'heavy', 'towards', 'enjoy',\n",
       "       'feeling', 'maybe', 'piece', 'fear', 'myself', 'stuff', 'handed',\n",
       "       'brings', 'movies', 'hospitals', 'rare', 'lots', 'skin', 'eating',\n",
       "       'intense', 'somewhat', 'liked', 'afraid', 'tribute', 'horror',\n",
       "       'revenge', 'brave', 'whilst', 'sympathy', 'assaulted', 'satisfying',\n",
       "       'hatred', 'viewer', 'awhile', 'pardon', 'delightful', 'disgust',\n",
       "       'imitation', 'pudding', 'cringe', 'jaded', 'pun', 'pangs', 'doesn',\n",
       "       'junctures', 'hellraiser', 'appologize'], \n",
       "      dtype='<U98')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_w2v = CountVectorizer(vocabulary=w.index2word)\n",
    "vect_w2v.fit(text_train_sub)\n",
    "docs = vect_w2v.inverse_transform(vect_w2v.transform(text_train_sub))\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = np.vstack([np.mean(w[doc], axis=0) for doc in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18750, 300)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docs_val = vect_w2v.inverse_transform(vect_w2v.transform(text_val))\n",
    "X_val = np.vstack([np.mean(w[doc], axis=0) for doc in docs_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86762666666666666"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_w2v = LogisticRegression(C=100).fit(X_train, y_train_sub)\n",
    "lr_w2v.score(X_train, y_train_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85711999999999999"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_w2f.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=500).fit(X_train, y_train_sub)\n",
    "rf.score(X_train, y_train_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81599999999999995"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Arithmetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7118192911148071),\n",
       " ('monarch', 0.6189674139022827),\n",
       " ('princess', 0.5902431607246399)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.most_similar(positive=['woman', 'king'], negative=['man'], topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('she', 0.8492251634597778),\n",
       " ('She', 0.6329933404922485),\n",
       " ('her', 0.6029669046401978)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.most_similar(positive=['woman', 'he'], negative=['man'], topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bratwurst', 0.5436394810676575),\n",
       " ('Domino_pizza', 0.5133179426193237),\n",
       " ('donuts', 0.5121968984603882)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.most_similar(positive=['Germany', 'pizza'], negative=['Italy'], topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words_in_data = list(set(word for doc in docs for word in doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_train = np.vstack(w[words_in_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45478, 300)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "words_train =TSNE().fit_transform(w.syn0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2Vec with gensim\n",
    "Also see https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/doc2vec-lee.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_corpus(text, tokens_only=False):\n",
    "    for i, line in enumerate(text):\n",
    "        if tokens_only:\n",
    "            yield gensim.utils.simple_preprocess(line)\n",
    "        else:\n",
    "            # For training data, add tags\n",
    "            yield gensim.models.doc2vec.TaggedDocument(gensim.utils.simple_preprocess(line), [i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_corpus = list(read_corpus(text_train_sub))\n",
    "test_corpus = list(read_corpus(text_val, tokens_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['maybe', 'it', 'just', 'because', 'have', 'an', 'intense', 'fear', 'of', 'hospitals', 'and', 'medical', 'stuff', 'but', 'this', 'one', 'got', 'under', 'my', 'skin', 'pardon', 'the', 'pun', 'this', 'piece', 'is', 'brave', 'not', 'afraid', 'to', 'go', 'over', 'the', 'top', 'and', 'as', 'satisfying', 'as', 'they', 'come', 'in', 'terms', 'of', 'revenge', 'movies', 'not', 'only', 'did', 'find', 'myself', 'feeling', 'lots', 'of', 'hatred', 'for', 'the', 'screwer', 'and', 'lots', 'of', 'sympathy', 'towards', 'the', 'screwee', 'felt', 'myself', 'cringe', 'and', 'feel', 'pangs', 'of', 'disgust', 'at', 'certain', 'junctures', 'which', 'is', 'really', 'rare', 'and', 'delightful', 'thing', 'for', 'somewhat', 'jaded', 'horror', 'viewer', 'like', 'myself', 'some', 'parts', 'are', 'very', 'reminiscant', 'of', 'hellraiser', 'but', 'come', 'off', 'as', 'tribute', 'rather', 'than', 'imitation', 'it', 'heavy', 'handed', 'piece', 'that', 'does', 'not', 'offer', 'the', 'viewer', 'much', 'to', 'consider', 'but', 'enjoy', 'being', 'assaulted', 'by', 'film', 'once', 'and', 'awhile', 'this', 'piece', 'brings', 'it', 'and', 'doesn', 'appologize', 'liked', 'this', 'one', 'lot', 'do', 'not', 'watch', 'whilst', 'eating', 'pudding'], tags=[0]),\n",
       " TaggedDocument(words=['sophmoric', 'this', 'film', 'is', 'but', 'it', 'is', 'funny', 'as', 'all', 'get', 'out', 'it', 'shows', 'the', 'boys', 'locker', 'room', 'mentality', 'being', 'played', 'by', 'the', 'other', 'side', 'it', 'is', 'good', 'to', 'see', 'such', 'tides', 'turned', 'and', 'how', 'silly', 'they', 'are', 'but', 'that', 'probably', 'not', 'news', 'to', 'most', 'women', 'cause', 'just', 'ask', 'one', 'they', 've', 'heard', 'em', 'all', 'before', 'watch', 'it', 'with', 'small', 'group', 'or', 'party', 'of', 'mixed', 'gender', 'and', 'of', 'the', 'room', 'will', 'laugh', 'for', 'hours', 'straight', 'and', 'the', 'other', 'can', 'you', 'ever', 'really', 'please', 'them'], tags=[1])]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec(size=50, min_count=2, iter=55)\n",
    "model.build_vocab(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.train(train_corpus, total_examples=model.corpus_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectors = [model.infer_vector(train_corpus[doc_id].words)\n",
    "          for doc_id in range(len(train_corpus))]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.vstack(vectors)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
